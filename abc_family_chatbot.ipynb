{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04efde-4373-4653-b3b6-a862214de544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat, Options\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a pre-trained sentence transformer model to create embeddings\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c3b1b-690a-424e-834e-38a1e6d0ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# URI examples: \"neo4j://localhost\", \"neo4j+s://xxx.databases.neo4j.io\"\n",
    "URI = \"neo4j://localhost:7687\"\n",
    "AUTH = (\"neo4j\", \"YourPassword123$!\")\n",
    "\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "session = driver.session(database=\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e9d81-e6bf-4d96-bc27-92ed07fd021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with an empty database.\n",
    "clean_slate_cypher = \"match (n) with n detach delete n\"\n",
    "session.run(clean_slate_cypher)\n",
    "\n",
    "# Load the Windsors family tree into the graph database.\n",
    "family_tree_cypher = \"\"\"\n",
    "CREATE (n01:Person {name: \"Adam Adams\", gender: \"male\", died: date(\"1952-02-06\") }),\n",
    " (n02:Person {name: \"Adelle Adams\", gender: \"female\", died: date(\"2022-03-30\") }),\n",
    " (n01)-[:MARRIED {from: date(\"1923-04-26\"), to: date(\"1952-02-06\")}]->(n02),\n",
    "\n",
    " (n03:Person {name: \"Angie Bond\", gender: \"female\", died: date(\"2022-09-08\") }),\n",
    " (n04:Person {name: \"Aaron Bond\", gender: \"male\", died: date(\"2021-04-09\") }),\n",
    " (n01)-[:IS_FATHER_OF]->(n03),\n",
    " (n02)-[:IS_MOTHER_OF]->(n03),\n",
    " (n03)-[:MARRIED {from: date(\"1947-11-20\"), to: date(\"2021-04-09\")}]->(n04),\n",
    "\n",
    " (n05:Person {name: \"Brittany Adams\", gender: \"female\", died: date(\"2002-02-02\") }),\n",
    " (n01)-[:IS_FATHER_OF]->(n05),\n",
    " (n02)-[:IS_MOTHER_OF]->(n05),\n",
    "\n",
    " (n06:Person {name: \"Bob Bond\", gender: \"male\" }),\n",
    " (n07:Person {name: \"Bonnie Bond\", gender: \"female\", died: date(\"1997-08-31\") }),\n",
    " (n08:Person {name: \"Brandy Bond\", gender: \"female\" }),\n",
    " (n04)-[:IS_FATHER_OF]->(n06),\n",
    " (n03)-[:IS_MOTHER_OF]->(n06),\n",
    " (n06)-[:MARRIED {from: date(\"1981-07-29\"), to: date(\"1996-08-28\")}]->(n07),\n",
    " (n06)-[:MARRIED {from: date(\"2005-04-09\"), to: \"present\"}]->(n08),\n",
    "\n",
    " (n09:Person {name: \"Anne Cox\", gender: \"female\" }),\n",
    " (n21:Person {name: \"Addison Carr\", gender: \"male\" }),\n",
    " (n22:Person {name: \"Ashton Cox\", gender: \"male\" }),\n",
    " (n04)-[:IS_FATHER_OF]->(n09),\n",
    " (n03)-[:IS_MOTHER_OF]->(n09),\n",
    " (n09)-[:MARRIED {from: date(\"1973-11-14\"), to: date(\"1992-04-28\")}]->(n21),\n",
    " (n09)-[:MARRIED {from: date(\"1992-12-12\"), to: \"present\"}]->(n22),\n",
    " \n",
    " (n10:Person {name: \"Brian Bond\", gender: \"male\" }),\n",
    " (n23:Person {name: \"Bethany Bond\", gender: \"female\" }),\n",
    " (n04)-[:IS_FATHER_OF]->(n10),\n",
    " (n03)-[:IS_MOTHER_OF]->(n10),\n",
    " (n10)-[:MARRIED {from: date(\"1986-07-23\"), to: date(\"1996-05-30\")}]->(n23),\n",
    " \n",
    " (n11:Person {name: \"Baxter Bond\", gender: \"male\" }),\n",
    " (n24:Person {name: \"Brianna Bond\", gender: \"female\" }),\n",
    " (n04)-[:IS_FATHER_OF]->(n11),\n",
    " (n03)-[:IS_MOTHER_OF]->(n11),\n",
    " (n11)-[:MARRIED {from: date(\"1999-06-19\"), to: \"present\"}]->(n24),\n",
    "\n",
    " (n25:Person {name: \"Cindy Bond\", gender: \"female\" }),\n",
    " (n26:Person {name: \"Callie Bond\", gender: \"female\" }),\n",
    " (n11)-[:IS_FATHER_OF]->(n25),\n",
    " (n24)-[:IS_MOTHER_OF]->(n25),\n",
    " (n11)-[:IS_FATHER_OF]->(n26),\n",
    " (n24)-[:IS_MOTHER_OF]->(n26),\n",
    "\n",
    " (n12:Person {name: \"Curt Bond\", gender: \"male\" }),\n",
    " (n14:Person {name: \"Clara Bond\", gender: \"female\" }),\n",
    " (n06)-[:IS_FATHER_OF]->(n12),\n",
    " (n07)-[:IS_MOTHER_OF]->(n12),\n",
    " (n12)-[:MARRIED {from: date(\"2011-04-29\"), to: \"present\"}]->(n14),\n",
    "\n",
    " (n13:Person {name: \"Chris Bond\", gender: \"male\" }),\n",
    " (n15:Person {name: \"Connie Bond\", gender: \"female\" }),\n",
    " (n06)-[:IS_FATHER_OF]->(n13),\n",
    " (n07)-[:IS_MOTHER_OF]->(n13),\n",
    " (n13)-[:MARRIED {from: date(\"2018-05-19\"), to: \"present\"}]->(n15),\n",
    "\n",
    " (n27:Person {name: \"Amber Cook\", gender: \"female\" }),\n",
    " (n28:Person {name: \"Anthony Cook\", gender: \"male\" }),\n",
    " (n10)-[:IS_FATHER_OF]->(n27),\n",
    " (n23)-[:IS_MOTHER_OF]->(n27),\n",
    " (n27)-[:MARRIED {from: date(\"2020-07-17\"), to: \"present\"}]->(n28), \n",
    "\n",
    " (n29:Person {name: \"Angelica Cruz\", gender: \"female\" }),\n",
    " (n30:Person {name: \"Aubrey Cruz\", gender: \"male\" }),\n",
    " (n10)-[:IS_FATHER_OF]->(n29),\n",
    " (n23)-[:IS_MOTHER_OF]->(n29),\n",
    " (n29)-[:MARRIED {from: date(\"2018-10-12\"), to: \"present\"}]->(n30),\n",
    "\n",
    " (n31:Person {name: \"Burt Carr\", img: \"n31.jpeg\", gender: \"male\" }),\n",
    " (n32:Person {name: \"Bronwyn Carr\", img: \"n32.jpeg\", gender: \"female\" }),\n",
    " (n21)-[:IS_FATHER_OF]->(n31),\n",
    " (n09)-[:IS_MOTHER_OF]->(n31),\n",
    " (n31)-[:MARRIED {from: date(\"2008-05-17\"), to: date(\"2020-02-22\")}]->(n32), \n",
    "\n",
    " (n35:Person {name: \"Amelia Diaz\", img: \"n35.jpeg\", gender: \"female\" }),\n",
    " (n36:Person {name: \"Arun Diaz\", img: \"n36.jpeg\", gender: \"male\" }),\n",
    " (n21)-[:IS_FATHER_OF]->(n35),\n",
    " (n09)-[:IS_MOTHER_OF]->(n35),\n",
    " (n35)-[:MARRIED {from: date(\"2011-07-30\"), to: \"present\"}]->(n36), \n",
    "\n",
    " (n16:Person {name: \"Dylan Bond\", gender: \"male\" }),\n",
    " (n17:Person {name: \"Daisy Bond\", gender: \"female\" }),\n",
    " (n18:Person {name: \"Dean Bond\", gender: \"male\" }),\n",
    " (n12)-[:IS_FATHER_OF]->(n16),\n",
    " (n14)-[:IS_MOTHER_OF]->(n16),\n",
    " (n12)-[:IS_FATHER_OF]->(n17),\n",
    " (n14)-[:IS_MOTHER_OF]->(n17),\n",
    " (n12)-[:IS_FATHER_OF]->(n18),\n",
    " (n14)-[:IS_MOTHER_OF]->(n18),\n",
    "\n",
    " (n19:Person {name: \"Daniel Bond\", gender: \"male\" }),\n",
    " (n20:Person {name: \"Demi Bond\", gender: \"female\" }),\n",
    " (n13)-[:IS_FATHER_OF]->(n19),\n",
    " (n15)-[:IS_MOTHER_OF]->(n19),\n",
    " (n13)-[:IS_FATHER_OF]->(n20),\n",
    " (n15)-[:IS_MOTHER_OF]->(n20),\n",
    " \n",
    " (n33:Person {name: \"Carla Carr\", gender: \"female\" }),\n",
    " (n34:Person {name: \"Christy Carr\", gender: \"female\" }),\n",
    " (n31)-[:IS_FATHER_OF]->(n33),\n",
    " (n32)-[:IS_MOTHER_OF]->(n33),\n",
    " (n31)-[:IS_FATHER_OF]->(n34),\n",
    " (n32)-[:IS_MOTHER_OF]->(n34),\n",
    "\n",
    " (n37:Person {name: \"Betty Diaz\", gender: \"female\" }),\n",
    " (n38:Person {name: \"Brooke Diaz\", gender: \"female\" }),\n",
    " (n39:Person {name: \"Brad Diaz\", gender: \"male\" }),\n",
    " (n36)-[:IS_FATHER_OF]->(n37),\n",
    " (n35)-[:IS_MOTHER_OF]->(n37),\n",
    " (n36)-[:IS_FATHER_OF]->(n38),\n",
    " (n35)-[:IS_MOTHER_OF]->(n38),\n",
    " (n36)-[:IS_FATHER_OF]->(n39),\n",
    " (n35)-[:IS_MOTHER_OF]->(n39),\n",
    "\n",
    " (n40:Person {name: \"Ben Cruz\", gender: \"male\" }),\n",
    " (n41:Person {name: \"Brandon Cruz\", gender: \"male\" }),\n",
    " (n30)-[:IS_FATHER_OF]->(n40),\n",
    " (n29)-[:IS_MOTHER_OF]->(n40),\n",
    " (n30)-[:IS_FATHER_OF]->(n41),\n",
    " (n29)-[:IS_MOTHER_OF]->(n41),\n",
    " \n",
    " (n42:Person {name: \"Belle Cook\", gender: \"female\" }),\n",
    " (n28)-[:IS_FATHER_OF]->(n42),\n",
    " (n27)-[:IS_MOTHER_OF]->(n42),\n",
    "\n",
    " (n100:Beverage {name: \"Pepsi\", can_cost: \"$0.72\"}),\n",
    " (n101:Beverage {name: \"Coca Cola\", can_cost: \"$0.70\"}),\n",
    " (n102:Beverage {name: \"Ginger Ale\", can_cost: \"$0.75\"}),\n",
    " (n16)-[:LIKES]->(n100),\n",
    " (n17)-[:LIKES]->(n101),\n",
    " (n18)-[:LIKES]->(n102),\n",
    " (n19)-[:LIKES]->(n101),\n",
    " (n20)-[:LIKES]->(n102),\n",
    " (n33)-[:LIKES]->(n100),\n",
    " (n34)-[:LIKES]->(n101),\n",
    " (n37)-[:LIKES]->(n101),\n",
    " (n38)-[:LIKES]->(n100),\n",
    " (n39)-[:LIKES]->(n100),\n",
    " (n40)-[:LIKES]->(n100),\n",
    " (n41)-[:LIKES]->(n101),\n",
    " (n42)-[:LIKES]->(n102);\n",
    "\"\"\"\n",
    "session.run(family_tree_cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f2fa4-1782-4972-9341-f8617a0c34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sentences in graph to match properties and relationships.\n",
    "person_node_query = \"\"\"\n",
    "    MATCH (p:Person) \n",
    "        SET p.sentence = p.name + ' is ' + p.gender \n",
    "    WITH p WHERE p.died IS NOT NULL \n",
    "        SET p.sentence = p.sentence + ' and died on ' + p.died \n",
    "    RETURN count(p) as ct\n",
    "    \"\"\"\n",
    "beverage_node_query = \"\"\"\n",
    "    MATCH (b:Beverage) \n",
    "        SET b.sentence = 'One can of ' + b.name + ' beverage costs ' + b.can_cost \n",
    "    RETURN count(b) as ct\n",
    "    \"\"\"\n",
    "person_rel_query = \"\"\"\n",
    "    MATCH (a:Person)-[r]->(b:Person) \n",
    "        SET r.sentence = a.name + ' ' + replace(tolower(type(r)),'_',' ') + ' ' + b.name \n",
    "    WITH r WHERE r.from IS NOT NULL \n",
    "        SET r.sentence = r.sentence + ' from ' + r.from + ' to ' + r.to\n",
    "    RETURN count(r) as ct\n",
    "    \"\"\"\n",
    "beverage_rel_query = \"\"\"\n",
    "    MATCH (a:Person)-[r]->(b:Beverage) \n",
    "        SET r.sentence = a.name + ' ' + replace(tolower(type(r)),'_',' ') + ' ' + b.name \n",
    "    RETURN count(r) as ct\n",
    "    \"\"\"\n",
    "queries = [person_node_query,beverage_node_query,person_rel_query,beverage_rel_query]\n",
    "for query in queries:\n",
    "    result = session.run(query)\n",
    "    print(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bfef5-d1db-4ef1-85b0-4cc6eb37817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences in nodes into embeddings, stored in the same node\n",
    "node_records = session.run(\"MATCH (n) RETURN elementId(n) as eid, n.sentence as sentence\")\n",
    "for n in node_records:\n",
    "    node_embedding = model.encode(n[1])\n",
    "    eid = n[0]\n",
    "    session.run(\"MATCH (n) WHERE elementId(n) = $eid SET n.embedding = $embedding\", \n",
    "           eid=eid, embedding=node_embedding)\n",
    "    \n",
    "# Convert sentences in relationships into embeddings, stored in the same relationship\n",
    "rel_records = session.run(\"MATCH ()-[r]->() RETURN elementId(r) as eid, r.sentence as sentence\")\n",
    "for r in rel_records:\n",
    "    rel_embedding = model.encode(r[1])\n",
    "    eid = r[0]\n",
    "    session.run(\"MATCH ()-[r]->() WHERE elementId(r) = $eid SET r.embedding = $embedding\", \n",
    "           eid=eid, embedding=rel_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3e24b-d815-4530-b10b-22764aaa5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector indexes for nodes containing embeddings.\n",
    "node_labels_query = \"MATCH (n) RETURN COLLECT(DISTINCT labels(n)[0]) as lbl\"\n",
    "node_labels = session.run(node_labels_query).data()[0]['lbl']\n",
    "print(node_labels)\n",
    "\n",
    "for lbl in node_labels:\n",
    "    # Drop preexisting vector indexes on nodes.\n",
    "    session.run(\"DROP INDEX \" + lbl + \"NodeVectorIdx IF EXISTS\")\n",
    "    \n",
    "    # Create new vector indexes on nodes.\n",
    "    node_index_query = f\"\"\"\n",
    "        CREATE VECTOR INDEX {lbl}NodeVectorIdx IF NOT EXISTS \n",
    "        FOR (n:{lbl}) \n",
    "        ON n.embedding\n",
    "        OPTIONS {{ indexConfig: {{\n",
    "         `vector.dimensions`: 384,\n",
    "         `vector.similarity_function`: 'cosine'\n",
    "        }}}}\n",
    "        \"\"\"\n",
    "    session.run(node_index_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaafa2-c751-4bfd-886d-523d40b5f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector indexes for relationships containing embeddings.\n",
    "rels_list_query = \"MATCH ()-[r]-() RETURN collect(distinct type(r)) as relTypes\"\n",
    "relTypes = session.run(rels_list_query).data()[0]['relTypes']\n",
    "print(relTypes)\n",
    "\n",
    "for rel in relTypes:\n",
    "    idxName = rel + \"_IDX\"\n",
    "    # Drop preexisting vector indexes on relationships.\n",
    "    session.run(\"DROP INDEX \" + idxName + \" IF EXISTS\")\n",
    "    \n",
    "    # Create new vector indexes on relationships.\n",
    "    rel_index_query = f\"\"\"\n",
    "        CREATE VECTOR INDEX {idxName} IF NOT EXISTS \n",
    "        FOR ()-[r:{rel}]-() \n",
    "        ON (r.embedding) \n",
    "        OPTIONS {{ indexConfig: {{ \n",
    "        `vector.dimensions`: 384, \n",
    "        `vector.similarity_function`:'cosine'}}}}\n",
    "        \"\"\"\n",
    "    session.run(rel_index_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4017d-a7bd-4f53-a799-dd23f4e49686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anticipate natural language questions that users might ask, each increasingly difficult to answer.\n",
    "question1 = \"who are Angie Bond's children?\"\n",
    "question2 = \"who are Baxter Bond's siblings?\"\n",
    "question3 = \"who are Bob Bond's grandchildren?\"\n",
    "question4 = \"how many spouses has Bob Bond had?\"\n",
    "question5 = \"which of Bob Bond's marriages produced children and how many?\"\n",
    "question6 = \"who are Adan Adams' great grandchildren?\"\n",
    "question7 = \"who are Carla Carr's first cousins on her father's side of the family?\"\n",
    "question8 = \"list each married couple in Adam Adams's bloodline and the duration of their marriages from longest to shortest\"\n",
    "question9 = \"\"\"\n",
    "    Bob Bond is throwing a party exclusively for his grandchildren. First identify who Bob's grandchildren are.\n",
    "    Next identify each grandkid's favorite beverage. If the grandkid is a boy, allocate him 5 cans of the beverage.\n",
    "    If the grandkid is a girl, allocate her 10 cans of the beverage. Then produce a list of beverage types, counts and costs.\n",
    "    \"\"\"\n",
    "\n",
    "# Choose one of the questions and embed it.\n",
    "question = question9\n",
    "question_embedding = model.encode(question)\n",
    "embedding_as_list = \",\".join(map(str, question_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec9238-9ea5-457b-afe0-41c4dbaf3103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search all graph indexes for similarity to the embedded question.\n",
    "vector_indexes_query = \"SHOW VECTOR INDEXES YIELD name, entityType, labelsOrTypes, properties\"\n",
    "vidx = session.run(vector_indexes_query)\n",
    "\n",
    "list_of_records = []\n",
    "mapping = { \n",
    "    'NODE': (\"queryNodes\", \"node\"),\n",
    "    'RELATIONSHIP': (\"queryRelationships\", \"relationship\") \n",
    "} \n",
    "vec_type = \"\"\n",
    "graph_type = \"\"\n",
    "\n",
    "for v in vidx: \n",
    "    if v[1] in mapping: \n",
    "        vec_type, graph_type = mapping[v[1]]\n",
    "        \n",
    "    query = f\"\"\"\n",
    "        WITH [{embedding_as_list}] AS embedding \n",
    "        CALL db.index.vector.{vec_type}('{v[0]}', 5, embedding) \n",
    "        YIELD {graph_type} as x, score \n",
    "        RETURN elementId(x) as eid, x.sentence as sentence, score\n",
    "        \"\"\"\n",
    "    idx_search = session.run(query)\n",
    "    for rec in idx_search: \n",
    "        list_of_records.append({\"graph\": graph_type, \"eid\": rec['eid'], \"sentence\": rec['sentence'], \"score\": rec['score']})\n",
    "            \n",
    "# Sort the resulting list in descending order by score.\n",
    "list_of_records.sort(key=lambda x: x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598af45a-173b-4207-8aa9-9b615c9cf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.75\n",
    "relevant_eids = []\n",
    "for z in list_of_records:\n",
    "    if z['score'] >= cutoff:\n",
    "        relevant_eids.append(z)\n",
    "        print(z['sentence'], \"(\", z['score'], \")\")\n",
    "\n",
    "if not relevant_eids:\n",
    "    print(\"*** Lower than usual relevancy! ***\\n\")\n",
    "    for z in list_of_records[0:25]:\n",
    "        relevant_eids.append(z)\n",
    "        print(z['sentence'], \"(\", z['score'], \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee94cf8-3a0a-4625-957f-88f604bad80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sentences = []\n",
    "for z in relevant_eids:\n",
    "    eid = z['eid']\n",
    "    \n",
    "    # If any of the top scores came from nodes, collect graph sentences as follows:\n",
    "    # 1. Get the sentence from the source node itself.\n",
    "    # 2. Get the sentences from all relationships connected to the source node.\n",
    "    # 3. Get the sentences from all nodes connected to those relationships.\n",
    "    # 4. Traverse one more hop outwards from the nodes in step 3, getting all sentences\n",
    "    #    from the next layer of relationships and nodes.\n",
    "    if z['graph'] == \"node\":\n",
    "        cypher = f\"\"\"\n",
    "            MATCH (n) where elementId(n) = '{eid}'     \n",
    "            MATCH (n)-[r]-(n2)\n",
    "            OPTIONAL MATCH (n2)-[r2]-(n3)\n",
    "            UNWIND r as rs\n",
    "            UNWIND r2 as r2s\n",
    "            WITH rs.sentence as a, r2s.sentence as b, \n",
    "                n.sentence as c, n2.sentence as d, \n",
    "                n3.sentence as e\n",
    "            WITH collect(distinct a) + collect(distinct b) + \n",
    "                collect(distinct c) + collect(distinct d) + \n",
    "                collect(distinct e) as dups\n",
    "            UNWIND dups as dup\n",
    "            RETURN collect(distinct dup) as uni\n",
    "            \"\"\"\n",
    "        result = session.run(cypher)\n",
    "        for sen in result.data()[0]['uni']:\n",
    "            prompt_sentences.append(sen)\n",
    "    \n",
    "    # If any of the top score came from relationships, collect graph senteces as follows:\n",
    "    # 1. Get the sentence from the source relationship itself.\n",
    "    # 2. Get the sentences from both nodes connected to the source relationship.\n",
    "    # 3. For each of the two nodes, traverse one hop outwards, capturing sentences\n",
    "    #    for each relationship and node in the expanded paths.    \n",
    "    if z['graph'] == \"relationship\":\n",
    "        cypher = f\"\"\"\n",
    "            MATCH (n1)-[r]-(n2) where elementId(r) = '{eid}' \n",
    "            OPTIONAL MATCH (n1)-[r2]-(n3)\n",
    "            OPTIONAL MATCH (n2)-[r3]-(n4)\n",
    "            UNWIND r2 as r2x\n",
    "            UNWIND r3 as r3x\n",
    "            WITH r.sentence as r01, r2x.sentence as r02, r3x.sentence as r03, \n",
    "                n1.sentence as a, n2.sentence as b, n3.sentence as c, n4.sentence as d\n",
    "            WITH collect(distinct a) + collect(distinct b) + collect(distinct c) + \n",
    "                collect(distinct d) + collect(distinct r01) + collect(distinct r02) + collect(distinct r03) as dups\n",
    "            UNWIND dups as dup\n",
    "            RETURN collect(distinct dup) as uni\n",
    "            \"\"\"\n",
    "        result = session.run(cypher)\n",
    "        for sen in result.data()[0]['uni']:\n",
    "            prompt_sentences.append(sen)\n",
    "\n",
    "prompt_sentences = sorted(set(prompt_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b0a7a-7b9e-40e2-81df-c456bec7f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prompt that directs the LLM to answer the user's question based on\n",
    "# the knowledge from the collection of sentences pulled from the graph.\n",
    "knowledge = \". \\n\".join(map(str, prompt_sentences))\n",
    "#print(knowledge)\n",
    "\n",
    "# Test the impact of larger graph traversals on the quality of the LLM's answer.\n",
    "prompt = \"You understand the logic of family genealogy. \"\n",
    "prompt += \"You have the following context: \" + knowledge + \". \" \n",
    "prompt += \" \\n---------------\\n \"\n",
    "prompt += \"Using the logic of that background information, \"\n",
    "prompt += \"and keeping the answer under 50 words, solve the following: \"\n",
    "prompt += question\n",
    "\n",
    "print(prompt)\n",
    "print(\" ------------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280264c4-c853-4b56-9f4c-5212813fc0ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = chat(\n",
    "    model=\"llama3.2\",  # Or llama3.2 or qwen2.5 or qwq or deepseek-r1:14b or deepseek-r1:32b\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    options=Options(\n",
    "        temperature=0.1,  # Controls randomness of output\n",
    "        num_ctx=1024,     # Sets the maximum number of tokens in the context window\n",
    "        top_k=50,          # Limits the number of tokens considered for each prediction\n",
    "        top_p=0.95,        # Limits the cumulative probability of tokens considered\n",
    "        repeat_penalty=1.1 # Penalizes repeating tokens\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c455da9-96f9-4809-85e6-fad73c501f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
